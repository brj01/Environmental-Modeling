{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7e1ac91-538d-4ec3-9a84-8b382509c4da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is a simple model of LUE using only one simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a595f06-4ffd-49c2-81c8-ed3535753ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pandas as pd \n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebd51d90-3032-4dfe-9781-74be85cd6788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initializing parameters and calculating \"true\" GPP and respiration values using these and the observational data arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d77e0a5a-ace7-492f-88d7-ba73ebaa1a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/08/8jyc_5897b9bsrrntp1y9jl40000gn/T/ipykernel_51358/3145669537.py:64: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv('simulation.txt', delim_whitespace=True)  # use sep=',' if it's comma-delimited\n"
     ]
    }
   ],
   "source": [
    "nb_iterations = 2000 # number of iterations \n",
    "n = 1 # number of jobs, hardcoded to 1 to create shape of parameter file\n",
    "file_path = 'parameters1.txt'\n",
    "\n",
    "# randomization of parameters using given low and high conditions \n",
    "LUE0 = np.random.uniform(low=0.02,high=0.05,size=n) \n",
    "PmaxL = np.random.uniform(low=1.0,high=200.0,size=n) \n",
    "extk = np.random.uniform(low=.2,high=1.6,size=n) \n",
    "D_0 = np.random.uniform(low=1.0,high=9.0,size=n) \n",
    "R_eco = np.random.uniform(low=1.0,high=50.0,size=n) \n",
    "Q_10  = np.random.uniform(low=1.0,high=3.0,size=n) \n",
    "\n",
    "# creation of txt files with parameter headers\n",
    "p1 = np.vstack((LUE0, PmaxL, extk, D_0, R_eco, Q_10))\n",
    "header=['LUE0','PmaxL','extk','D_0','R_eco', 'Q_10']\n",
    "p2 = pd.DataFrame(p1.T,columns = header)\n",
    "p2.to_csv('parameters1.txt', sep=' ', index=False)\n",
    "\n",
    "# reading in observational data for gpp and respiration calculation, vector arrays\n",
    "df_obs = pd.read_csv('face9806odd_input.csv')\n",
    "Ta_array = df_obs['Ta'][2:].to_numpy() \n",
    "PAR_array = df_obs['PAR'][2:].to_numpy()\n",
    "LAI_array = df_obs['LAI'][2:].to_numpy()\n",
    "VPD_array = df_obs['VPD'][2:].to_numpy()\n",
    "Ta_array = np.array(Ta_array, dtype=float)\n",
    "PAR_array = np.array(PAR_array, dtype=float)\n",
    "LAI_array = np.array(LAI_array, dtype=float)\n",
    "VPD_array = np.array(VPD_array, dtype=float)\n",
    "\n",
    "# setting initial parameter values as those randomly generated above \n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    headers = lines[0].strip().split()\n",
    "    values = lines[1].strip().split()\n",
    "lue0 = float(values[0]) \n",
    "pmaxl = float(values[1])\n",
    "extk = float(values[2])  \n",
    "d_0 = float(values[3])   \n",
    "r_eco = float(values[4])  \n",
    "q_10 = float(values[5] )  \n",
    "\n",
    "# calculate gpp and respiration, which will be used as the \"true observational\" values \n",
    "resp=(r_eco)*(q_10**(Ta_array/10.0))        \n",
    "gpp =((pmaxl/extk)*np.log((pmaxl+lue0*PAR_array)/((pmaxl+lue0*PAR_array)*np.exp(-extk*LAI_array)))/(1.0+(VPD_array/d_0)))\n",
    "\n",
    "# create files for running.txt (running values of currently accepted parameters to be used in the calculation; initially set to initial paremters)\n",
    "# creates accepted.txt (list of all accepted parameters, includes initial params in first line)\n",
    "# calculates \"observed\" gpp and resp and puts it in simulation.txt and extracts it into gpp_obsv and resp_obsv arrays\n",
    "# makes empty probability file \n",
    "\n",
    "file_path = 'running.txt' \n",
    "with open('running.txt', 'w') as f:\n",
    "    p2.to_csv('running.txt', sep=' ', index=False)\n",
    "file_path = 'accepted.txt' \n",
    "with open('accepted.txt', 'w') as f:\n",
    "    p2.to_csv('accepted.txt', sep=' ', index=False)\n",
    "with open('simulation.txt', 'w') as f:\n",
    "    f.write(\"gpp_obsv resp_obsv\\n\")\n",
    "    for i in range(len(gpp)):\n",
    "        f.write(f\"{gpp[i]} {resp[i]}\\n\")    \n",
    "file_path = 'prob.txt'\n",
    "with open('prob.txt', 'w') as f:\n",
    "    pass\n",
    "df = pd.read_csv('simulation.txt', delim_whitespace=True)  # use sep=',' if it's comma-delimited\n",
    "gpp_obsv = df['gpp_obsv'].to_numpy()\n",
    "resp_obsv = df['resp_obsv'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef7059ab-13b6-4dee-a98c-45ea20097397",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generatemcmc(runningfile):  # this function generates new parameters from most recent running one using random perturbations\n",
    "    with open(runningfile, 'r') as file:\n",
    "        r = np.random.uniform(low=-.5, high =.5, size=1) \n",
    "        D = .5 # harcoded to 0\n",
    "        lines = file.readlines()\n",
    "        headers = lines[0].strip().split()\n",
    "        values = lines[1].strip().split()\n",
    "        values = [v.strip('[]') for v in values]\n",
    "        values\n",
    "    lue0 = float(values[0]) + (r * ((.05 - .02) / D))\n",
    "    if lue0 > .05: # these lines of logic follow the circular logic of when parameter values are out of bounds\n",
    "        lue0 = .02 + (lue0-.05)\n",
    "    if lue0 < .02:\n",
    "        lue0 = (.05 - lue0) + .02\n",
    "    pmaxL = float(values[1]) + (r * ((200 - 1) / D))\n",
    "    if pmaxL > 200:\n",
    "        pmaxL = 1 + (pmaxL-200)\n",
    "    if pmaxL < 1:\n",
    "        pmaxL = (200 - pmaxL) + 1\n",
    "    extk = float(values[2]) +  (r * ((1.6 - .2) / D))\n",
    "    if extk > 1.6:\n",
    "            extk = .2 + (extk-1.6)\n",
    "    if extk < .2:\n",
    "            extk = (1.6 - extk) + .2\n",
    "    d_0 = float(values[3]) + (r * ((9 - 1) / D))\n",
    "    if d_0 > 9:\n",
    "            d_0 = 1 + (d_0-9)\n",
    "    if d_0 < 1:\n",
    "            d_0 = (9 - d_0) + 1\n",
    "    r_eco = float(values[4])  + (r * ((50 - 1) / D))\n",
    "    if r_eco > 50:\n",
    "            r_eco = 1 + (r_eco-50)\n",
    "    if r_eco < 1:\n",
    "            r_eco = (50 - r_eco) + 1\n",
    "    q_10 = float(values[5]) + (r * ((3 - 1) / D))\n",
    "    if q_10 > 3:\n",
    "            q_10 = 1 + (q_10 - 3)\n",
    "    if q_10 < 1:\n",
    "            q_10 = (3 - q_10) + 1\n",
    "    return lue0, pmaxL, extk, d_0, r_eco, q_10 # will return newly established parameters\n",
    "\n",
    "# main simulation function \n",
    "def simulation (nb_iteration, max_jobs):\n",
    "    for i in range (0, nb_iteration):    \n",
    "        lue0, pmaxL, extk, d_0, r_eco, q_10 = generatemcmc ('running.txt') # each iteration generates new parameters\n",
    "        for j in range(1, max_jobs + 1):\n",
    "            # calculates simulated resp and gpp based on the new generated parameters\n",
    "            resp_sim =(r_eco)*(q_10**(Ta_array/10.0))      \n",
    "            gpp_sim =((pmaxL/extk)*np.log((pmaxL+lue0*PAR_array)/((pmaxL+lue0*PAR_array)*np.exp(-extk*LAI_array)))/(1.0+(VPD_array/d_0)))\n",
    "            \n",
    "            # applies the mh alogorthim calculation for probability below for both variabiles, using difference between obsv and simulated values\n",
    "            gpp_sum = np.sum((gpp_obsv - gpp_sim)**2) / (2 * np.std(gpp_obsv)**2)\n",
    "            resp_sum = np.sum((resp_obsv - resp_sim)**2) / (2 * (0.5 * np.std(resp_obsv))**2) # scale factor of .5 here \n",
    "            \n",
    "            # calculates the corresponding probabiltiy of this iteration's parameters\n",
    "            prob = - (gpp_sum + resp_sum)\n",
    "            \n",
    "        \n",
    "            if i == 0: # edge case: this condition ensures that the initial run uses the calculated probability regardless as there is no previous probability to compare to\n",
    "                with open('prob.txt', 'w') as f:\n",
    "                    f.write(str(log_prob) + '\\n')\n",
    "            # otherwise, it reads the most recently accepted probability, compares it, and uses mh conditions to see if prob.txt should be accepted, which in turn updates running.txt with the current parameters used,\n",
    "            # appends to accepted.txt\n",
    "            # this new probability and newly accepted parameters are then used to compare with the next iteration \n",
    "            with open('prob.txt', 'r') as f:\n",
    "                first_line = f.readline().strip()\n",
    "                prob_prev = float(first_line)\n",
    "                u = np.random.uniform(0, 1)\n",
    "                delta = prob - prob_prev\n",
    "                if delta >= 0 or np.log(u) < delta:\n",
    "                    with open('prob.txt', 'w') as f:\n",
    "                        f.write(str(prob) + '\\n')\n",
    "                    with open('running.txt', 'r') as f:\n",
    "                        lines = f.readlines()\n",
    "                        new_params = f\"{lue0} {pmaxL} {extk} {d_0} {r_eco} {q_10}\\n\"\n",
    "                        lines[1] = new_params\n",
    "                    with open('running.txt', 'w') as f:\n",
    "                        f.writelines(lines)\n",
    "                    with open('accepted.txt', 'a') as f:\n",
    "                        f.write(f\"{lue0} {pmaxL} {extk} {d_0} {r_eco} {q_10}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d40c388e-6d86-412d-8a37-8b5ed7638b51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_prob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msimulation\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 61\u001b[0m, in \u001b[0;36msimulation\u001b[0;34m(nb_iteration, max_jobs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m# edge case: this condition ensures that the initial run uses the calculated probability regardless as there is no previous probability to compare to\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprob.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 61\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28mstr\u001b[39m(\u001b[43mlog_prob\u001b[49m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# otherwise, it reads the most recently accepted probability, compares it, and uses mh conditions to see if prob.txt should be accepted, which in turn updates running.txt with the current parameters used,\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# appends to accepted.txt\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# this new probability and newly accepted parameters are then used to compare with the next iteration \u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprob.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log_prob' is not defined"
     ]
    }
   ],
   "source": [
    "simulation (2000, 1) # runs simulation with 2000 iterations and 1 job; outputs accepted.txt (all accepted params), parameters1.txt (initial params to be used as \"true values\", prob.txt (running probability, running.txt (most recently accepted set of params), and simulation.txt (calculation of gpp and resp from initial values to be used as \"truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49529df9-6dc8-48b6-9874-398b478346d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
