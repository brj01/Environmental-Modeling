{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a595f06-4ffd-49c2-81c8-ed3535753ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pandas as pd \n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d77e0a5a-ace7-492f-88d7-ba73ebaa1a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1162266296.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    def generate_parametersmcmc('running.txt', nb_iteration)\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def simulation_fnc(j, Ta, VPD, PAR, LAI_h, NEE_obs, Fcgpf):\n",
    "    file_path =  f'parameters{j}.txt'\n",
    "    with open(f'simulation{j}.txt', 'w') as file_sim:\n",
    "        file_sim.write(\"R_hetero GPP\\n\")\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for i in range (1, len(lines)):\n",
    "            line = lines[i]\n",
    "            values = line.split()\n",
    "            R_hetero=float(values[4])*(float(values[5])**(Ta/10.0)) \n",
    "            GPP = float(values[1]) / float(values[2]) * np.log((float(values[1]) + float(values[0]) * PAR) / float(values[1]) + float(values[0]) * PAR * exp (-1 * float(values[2]) * LAI_h))\n",
    "            with open(f'simulation{j}.txt', 'a') as file_sim:\n",
    "                file_sim.write(\"{R_hetero} {GPP}\\n\") # some GPP values for sims are straight 0 for each parameter\n",
    "                \n",
    "def generate_parametersmcmc(runningtxt, nb_iteration)\n",
    "    data = pd.read_csv('running.txt', delim_whitespace=True)\n",
    "    param_min = np.array(.02, 1.0, .2, 1.0, 1.0. 1.0)\n",
    "    param_max = np.array(.05, 200.0, 1.6, 9.0, 50.0, 3.0)\n",
    "    range = ((param_max - param_min ) / nb_iteration)\n",
    "    for i in range (len(data))\n",
    "        r = np.random.uniform(low=-0.5, high=0.5, size=data.shape[1])\n",
    "        # some lines below is gotten using online reference to translate between fortran and python so need to run through and check values \n",
    "        data.iloc[i] = ck.iloc[i].to_numpy() + np.multiply(r, range_step)\n",
    "        compare_min = data.iloc[i] < param_min\n",
    "        res_min = np.nonzero(compare_min)[0]\n",
    "        data.iloc[i][res_min] = param_max[res_min] - (param_min[res_min] - sata.iloc[i][res_min])\n",
    "        compare_max = data.iloc[i] > param_max\n",
    "        res_max = np.nonzero(compare_max)[0]\n",
    "        data.iloc[i][res_max] = param_min[res_max] + (daa.iloc[i][res_max] - param_max[res_max])\n",
    "    with open('parameters.txt','a') as f:\n",
    "        f.write(data.to_string(header=True,index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef7059ab-13b6-4dee-a98c-45ea20097397",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (532386012.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    PmaxL = np.random.uniform(low=1.0,high=200.0,size=n)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "### generate the initial parameters - imitiating generate_parameters_i\n",
    "\n",
    "nb_iteration= 78890 # rows in the observational data column\n",
    "n = max_jobs=5 # confirmed to have 5 jobs for now \n",
    "obs = pd.read_csv('face9806odd_input.csv')\n",
    "\n",
    "file_path = 'parameters.txt' \n",
    "        LUE0 = np.random.uniform(low=0.02,high=0.05,size=n) \n",
    "        PmaxL = np.random.uniform(low=1.0,high=200.0,size=n) \n",
    "        extk = np.random.uniform(low=.2,high=1.6,size=n) \n",
    "        D_0 = np.random.uniform(low=1.0,high=9.0,size=n) \n",
    "        R_eco = np.random.uniform(low=1.0,high=50.0,size=n) \n",
    "        Q_10  = np.random.uniform(low=1.0,high=3.0,size=n) \n",
    "        p1 = np.vstack((LUE0, PmaxL, extk, D_0, R_eco, Q_10))\n",
    "        header=['LUE0','PmaxL','extk','D_0','R_eco', 'Q_10']\n",
    "        p2 = pd.DataFrame(p1.T,columns = header)\n",
    "        with open(file_path,'a') as f: # file with initial parameters \n",
    "            f.write(p2.to_string(header=True,index=False))\n",
    "                \n",
    "for j in range(1, max_jobs + 1):  # parameter files based on job number\n",
    "            file_path = f'parameters{j}.txt' \n",
    "            LUE0 = np.random.uniform(low=0.02,high=0.05,size=n) \n",
    "            PmaxL = np.random.uniform(low=1.0,high=200.0,size=n) \n",
    "            extk = np.random.uniform(low=.2,high=1.6,size=n) \n",
    "            D_0 = np.random.uniform(low=1.0,high=9.0,size=n) \n",
    "            R_eco = np.random.uniform(low=1.0,high=50.0,size=n) \n",
    "            Q_10  = np.random.uniform(low=1.0,high=3.0,size=n) \n",
    "            p1 = np.vstack((LUE0, PmaxL, extk, D_0, R_eco, Q_10))\n",
    "            header=['LUE0','PmaxL','extk','D_0','R_eco', 'Q_10']\n",
    "            p2 = pd.DataFrame(p1.T,columns = header)\n",
    "            with open(file_path,'a') as f: # file with initial parameters \n",
    "                f.write(p2.to_string(header=True,index=False))\n",
    "\n",
    "\n",
    "file_path = 'accepted.txt' # where accepted parameters will be stored\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write('LUE0 PmaxL extk D_0 R_eco Q_10' + '\\n')\n",
    "    \n",
    "for i in range (1, nb_iteration - 1):\n",
    "    Ta = float(obs.iloc[i, 1])\n",
    "    VPD = float(obs.iloc[i, 2])\n",
    "    PAR = float(obs.iloc[i, 3])\n",
    "    LAI_h = float(obs.iloc[i, 4])\n",
    "    NEE_obs = float(obs.iloc[i, 5]) # confirm Fc with Mazen\n",
    "    Fcgpf = float(obs.iloc[i, 6])\n",
    "    generate_parameters()\n",
    "    for j in range(1, max_jobs + 1):  \n",
    "        simulation_fnc(j, Ta, VPD, PAR, LAI_h, NEE_obs, Fcgpf) # double check simulation 5\n",
    "        generatemcmc('running.txt', nb_iteration)\n",
    "        # accept or dont accept - this is where mh algo goes? then we can append to running.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
